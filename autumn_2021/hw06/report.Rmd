---
title: "Домашняя работа №6, Плеханов Антон 316"
output:
  html_document:
    df_print: paged
---

## t-тест Стьюдента

Сгенерируем выборку из нормального распределения размера 2000:
```{r}
set.seed(123)
X <- rnorm(2000, mean = 5, sd = 4)
mean(X)
```
Проверим гипотезу о том, что среднее истинного распрделения равно 5 с помощью t-критерия Стьюдента против двусторонней альтернативы. Уровень значимости теста положим равным 0.05:
```{r}
t.test(X, mu = 5, alternative = "two.sided")
```

(P-value - вероятность того, что тестируемая статистика примет наблюдаемое значение или более экстремальное при условии выполнения нулевой гипотезы. Если p-value выше заданного уровня значимости, то нулевая гипотеза принимается, иначе - принимается альтернатива)

P-value = 0.1905 > 0.05, следовательно, считаем нулевую гипотезу о равенстве истинного среднего пяти выполненной.
Также с помощью данного теста был построен доверительный интервал уровня 0.95 для выборочного среднего -  [4.941677, 5.292695].



Предположим, что мы обладаем некоторым априорным знанием о том, что выборка не может иметь среднее ниже/выше тестируемого значения. В таком случае в качестве альтернативы принимается одностороння гипотеза.
```{r}
t.test(X, mu = 5, alternative = "less", conf.level = 0.99)
```

P-value > 0.05, значит, нулевая гипотеза принимается. Также был построен доверительный интервал уровня 0.99 -  [-Inf, 5.325545]


Тест с правосторонней альтернативой + доверительный интервал уровня 0.9:
```{r}
t.test(X, mu = 5, alternative = "greater", conf.level = 0.9)
```


Оценка мощности критерия и объема выборки для достижения заданной мощности критерия реализуется с помощью функции power.t.test.

Оценим мощность критерия Стьюдента для двухсторонней гипотезы для одной выборки при заданном объеме выборки n = 2000, стандартным отклонением 4, уровнем значимости alpha = 0.05, delta = 0.5:
```{r}
power.t.test(n = 2000, delta = 0.5, sd = 4, sig.level = 0.05, 
             type = "one.sample", alternative = "two.sided")
```

В результате имеем: построенный по выборке размера 2000 с стандартным отклонением 4 критерий при уровне значимости 0.05 будет с вероятностью 0.9998 определять различие истинного и выборочного средних более 0.5.


Выясним, какого размера выборку (sd = 4) необходимо иметь, чтобы с помощью t-теста определять различие между средними 0.5 с вероятностью 0.9:
```{r}
power.t.test(power = 0.9, delta = 0.5, sd = 4, sig.level = 0.05, 
             type = "one.sample", alternative = "two.sided")
```

Необходимо иметь выборку размера 675.



Применение t-теста Стьюдента для двух выборок:
```{r}
set.seed(1234)
X <- rnorm(n = 500, mean = 1, sd = 2)
Y <- rnorm(n = 500, mean = 0.9, sd = 2)
```


```{r}
t.test(X, Y, var.equal = TRUE, 
       alternative = "two.sided", conf.level = 0.9)
```

P-value > 0.05, значит, данные не противоречат нулевой гипотезе о равенстве средних.

Можем заметить, что средние двух выборок заметно отличаются.
Проведем тест против гипотезы mean(X) > mean(Y):

```{r}
t.test(X, Y, var.equal = TRUE, 
       alternative = "greater", conf.level = 0.99)
```

Получили p-value < 0.05, следовательно, считаем выполненной альтернативную гипотезу.

Рассчитаем мощность построенного критерия:

```{r}
power.t.test(n = 500, delta = 0.1, sd = 2, sig.level = 0.05,
             type = "two.sample", alternative = "two.sided")
```

Критерий Стьюдента различает разность 0.1 между средними в случае верности альрнативной гипотезы (о неравенстве средних) с вероятностью 0.12 - довольно малая вероятность.

Рассчитаем размер выборок, необходимый для достижения мощности 0.8 при реальном различии средних 0.1:

```{r}
power.t.test(power = 0.8, delta = 0.1, sd = 2, sig.level = 0.05,
             type = "two.sample", alternative = "one.sided")
```

Необходимо иметь выборку размера 4947, чтобы с вероятностью 0.8 различить разность 0.1 между средними значениями выборок.

## Критерий Уилкоксона

Критерий Уилкоксона используется для проверки гипотезы о симметричности распределения с средним mu.

Сгенерируем две выборки (симметричную и несимметричную):

```{r}
set.seed(1234)
X <- rnorm(700)
Y <- rgamma(700, shape = 4, rate = 1)

hist(X, freq = FALSE)
hist(Y, freq = FALSE)
```

Проведем тест Уилкоксона для нормальной выборки:
```{r}
wilcox.test(X, mu = 0, alternative = "two.sided")
```

P-value > 0.05, следовательно нулевая гипотеза о симметричности распределения относительно нуля принимается.


Тест Уилкоксона для выборки из гамма-распределения:
```{r}
wilcox.test(Y, mu = mean(Y), alternative = "two.sided")
```

P-value < 0.05, следовательно, гипотеза о симметричности распределения отночительно mean(Y) == 4.07 отвергается.


## Критерий Уилкоксона-Манна-Уитни

Критерий Уилкоксона-Манна-Уитни - непараметрический аналог t-теста Стьюдента для проверки гипотезы о равенстве средних двух независимых выборок.

```{r}
set.seed(1234)
X <- rpois(n = 1000, lambda = 1)
Y <- rpois(n = 1000, lambda = 1.1)

hist(X, breaks = 50, col = "red")
hist(Y, breaks = 50, col = "red")
```


```{r}
mean(X)
mean(Y)
```

Проведем тест Уилкоксона-Манна-Уитни:
```{r}
wilcox.test(X, Y, alternative = "two.sided",
            conf.int = TRUE, conf.level = 0.99)
```

P-value > 0.05, следовательно, нулевая гипотеза о равенстве средних  принимается.
Также был построен 99% доверительный интервал для разности средних.



## Проверка гипотез об однородности дисперсий

### Тест Фишера

Необходимым условием применения теста Фишера является нормальное распределение выборок.
Сгенерируем две выборки размера 500 из нормальных распределений и проведем тест Фишера:
```{r}
set.seed(1234)
X <- rnorm(1000, mean = 1, sd = 2)
Y <- rnorm(1000, mean = 2, sd = 2.1)

var.test(X, Y, ratio = 1, conf.level = 0.9)
```

P-value > 0.05, значит, принимаем гипотезу о равенстве дисперсий.


### Тест Левене

Тест Левене также позволяет проверять гипотезу об однородности дисперсий, но позволяет проводить тест сразу для нескольких выборок (возможно из различных распределений).
Продемонстрируем на примере трех выборок (две из экспоненциального, одна из нормального) с равными дисперсиями:
```{r}
set.seed(12)
X1 <- rnorm(1000, mean = 0, sd = 1)
lab1 <- rep(1, 1000)
X2 <- rexp(900, rate = 1)
lab2 <- rep(2, 900)
X3 <- rexp(1100, rate = 1)
lab3 <- rep(3, 1100)

X <- c(X1, X2, X3)
labs <- as.factor(c(lab1, lab2, lab3))


library(car)
leveneTest(X ~ labs, center = mean)
```

p-value > 0.05, следовательно, нулевая гипотеза о равенстве диспресий считается выполненной.


### Критерий Бартлетта

Критерий Бартлетта позволяет проверять гипотезы об однородности двух и более выборок при предположении о их нормальной распределенности.

Пример использования:
```{r}
set.seed(1234)
X1 <- rnorm(1000, mean = 0, sd = 1)
lab1 <- rep(1, 1000)
X2 <- rnorm(900, mean = 3, sd = 1.06)
lab2 <- rep(2, 900)
X3 <- rnorm(1100, mean = 5, sd = 1)
lab3 <- rep(3, 1100)

X <- c(X1, X2, X3)
labs <- as.factor(c(lab1, lab2, lab3))


bartlett.test(X, labs)
```

В результате получили p-value > 0.05, следовательно, нулевая гипотеза о рванестве дисперсий принимается.


### Критерий Флингера-Килина

Критерий Флингера-Килина повзоляет проверять гипотезу об однородности дисперсий двух и более выборок, при этом не требует предположений об их нормальной распрделенности.


```{r}
set.seed(1234)
X1 <- rnorm(2000, mean = 0, sd = 2)
lab1 <- rep(1, 2000)
X2 <- rexp(3000, rate = 0.5)
lab2 <- rep(2, 3000)
X3 <- rnorm(2000, mean = 100, sd = 2)
lab3 <- rep(3, 2000)

sd(X1)
sd(X2)
sd(X3)

X <- c(X1, X2, X3)
labs <- as.factor(c(lab1, lab2, lab3))

fligner.test(X ~ labs)
```

p-value < 0.05, следовательно, отвергаем нулевую гипотезу, хотя теоретические дисперсии распределений равны.

Попробуем уменьшить размеры выборок:
```{r}
set.seed(1234)
X1 <- rnorm(20, mean = 0, sd = 2)
lab1 <- rep(1, 20)
X2 <- rexp(30, rate = 0.5)
lab2 <- rep(2, 30)
X3 <- rnorm(20, mean = 100, sd = 2)
lab3 <- rep(3, 20)

sd(X1)
sd(X2)
sd(X3)

X <- c(X1, X2, X3)
labs <- as.factor(c(lab1, lab2, lab3))

fligner.test(X ~ labs)
```

При меньших размерах выборки, даже с учетом того, что выборочные стандартные отконения отличаются сильнее, чем в случае с выборками размеров в 100 раз больше, получаем p-value > 0.05, т.е. нулевая гипотеза о равенстве дисперсий принимается. Различие в результатах можно объяснить тем, что, вообще говоря, различие в значениях статистик от больших выборок более значимо, чем такое же различие для выборок меньшего объема.



## Проверка гипотез на реальных данных

Загружаем данные:
```{r, message=FALSE, warning=FALSE}
data <- read.csv("C:\\Users\\antpl_0n4duwv\\Documents\\Studies\\prac\\moscow_apartment_listings.csv")
attach(data)
```

```{r}
str(data)
```

Есть довольно известное "народное" мнение о том, что квартиры на низких этажах обычно ниже в цене. Это связано, например, с вопросами безопасности: нередко можно увидеть решетки на окнах первых этажей домов с неогороженной территорией.

Построим диаграммы размаха для групп квартир с первого этажа и не с первого:
```{r}
first_floor <- as.factor(first_floor)
boxplot(price ~ first_floor, data, ylab = "Цена",
        xlab = "Первый этаж", names = c("Нет", "Да"))
```

```{r}
first_floor_price <- data[data$first_floor == 1, ]$price
non_first_floor_price <- data[data$first_floor == 0, ]$price

mean(first_floor_price)
mean(non_first_floor_price)
```

В рассматриваемых данных средние характеристики цены (медиана, среднее выборочное, квартили) для квартир первого этажа несколько ниже, чем для остальных.

Проверим, является ли это разница статистически значимой.

Сперва построим распределение цен для соответствущих групп:
```{r}
hist(first_floor_price, freq = FALSE, col = "red", 
     main = "Гистограмма цен квартир на первом этаже", 
     xlab = "Цена", ylab = "Вероятность")
hist(non_first_floor_price, freq = FALSE, col = "forestgreen",
     main = "Гистограмма цен квартир на этаже > 1",
     xlab = "Цена", ylab = "Вероятность")

```

Распределения имеют явно не нормальное распределение, поэтому t-тест Стьюдента не применим.
Воспользуемся тестом Уилкоксона:
```{r}
wilcox.test(price ~ first_floor, 
            alternative = "two.sided", paired = FALSE)
```

P-value < 0.05, значит, альтернативная гипотеза о более низких ценах квартир с первого этажа принимается.


2) Построим boxplot для распределений цены в зависимости от административного округа:

```{r}
AO <- as.factor(AO)

colours <- c("forestgreen", "magenta", "maroon2", "orange1", "royalblue2", "red", "skyblue3", "darkcyan", "coral")

boxplot(price ~ AO, main = "Распределение цен в зависимости от округа", ylab = "Администативный округ", xlab = "Цена", las = 1, col = colours, horizontal = TRUE)
legend(x = "bottomleft", legend = levels(AO), col = colours, fill = colours, cex = 0.44)
```


Проверим гипотезу об однородности дисперсий цены в различных административных округах с помощью теста Левена:
```{r}
leveneTest(price ~ first_floor)
leveneTest(price ~ first_floor, center = mean)
```

Результат, как и следовало ожидать исходя из интерквартильных расстояний, отрицательный - группы имеют неоднородные дисперсии.


Попробуем провести анализ однородности дисперсий для других групп.
Построим новый признак - фактор расстояния до центра Москвы.
```{r}
dist.factor <- cut(subway_dist_to_center, 
                   breaks = c(min(subway_dist_to_center) - 1, 5000, 10000, 15000, 20000, max(subway_dist_to_center) + 1), 
                   labels = c("[0, 5)", "[5, 10)", "[10, 15)", "[15, 20)", "[20, +inf)"))

data['dist_factor'] <- dist.factor
```


Построим диаграммы размахов для цен квартир в зависимости от значения dist_factor:
```{r}
boxplot(price ~ dist_factor, data, 
        col = c("royalblue2", "red", "orange1", "darkcyan", "coral"),
        xlab = "Расстояние до центра, км", ylab = "Цена, рубли", 
        lat = 4
        )
```

Исходя из графиков, можем сделать вывод, что все пять групп не обладают однородной дисперсией.
Подтвердим это с помощью критерия Левена (распределение цен квартир сильно отличается от нормального, так что другие критерии не применимы):

```{r}
leveneTest(price ~ dist_factor, data)
```

P-value < 0.05, следовательно, гипотеза об однородности дисперсий отвергается.

Также можно заметить, что интерквартильный размах схож у групп [0, 5) и [10, 15).
Проверим гипотезу о равенстве дисперсий для этих групп.

```{r}
hist(data[data$dist_factor == "[0, 5)", ]$price, freq = FALSE,
     main = "Распределение цены для группы [0, 5)",
     xlab = "Цена, рубли", ylab = "Вероятность")
hist(data[data$dist_factor == "[10, 15)", ]$price, freq = FALSE,
     main = "Распределение цены для группы [10, 15)",
     xlab = "Цена, рубли", ylab = "Вероятность")
```

Как уже замечалось ранее, распределние цен квартир достаточно далеко для нормального (по крайней мере на втором графике)

```{r}
X1 <- data[data$dist_factor == "[0, 5)", ]$price
X2 <- data[data$dist_factor == "[10, 15)", ]$price

sd(X1) / sd(X2)

X <- c(X1, X2)
labs <- as.factor(c(rep(0, length(X1)), rep(1, length(X2))))

leveneTest(X, labs)
leveneTest(X, labs, center = mean)
```

Результат: оба теста (с центральными характеристиками медианой и средним) выдают p-value > 0.05, значит, нулевая гипотеза о равенстве дисперсий принимается.


Подобные рассуждения для групп [10, 15) и [20, +inf) не проходят (различие дисперсий статистически значимо)
```{r}
X1 <- data[data$dist_factor == "[10, 15)", ]$price
X2 <- data[data$dist_factor == "[20, +inf)", ]$price

sd(X1) / sd(X2)

X <- c(X1, X2)
labs <- as.factor(c(rep(0, length(X1)), rep(1, length(X2))))

leveneTest(X, labs)
leveneTest(X, labs, center = mean)
```

